# -*- coding: utf-8 -*-
"""Data_Pre_processing.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SxHFWClwUqLyvBMkmPyZbPudzdV2HyWM

# Data Pre-processing
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

df=pd.read_csv('/content/Data.csv')
df

df_data3 = pd.read_csv('/content/Data3.csv')
df_data3

"""#create dependent and independent variables"""

#independent var
x=df.iloc[:,:-1].values
#dependent var
y=df.iloc[:,-1].values

x

"""# Missing values
1. method
"""

x

from sklearn.impute import SimpleImputer
imputer=SimpleImputer(missing_values=np.nan, strategy='mean')
imputer.fit(x[:,1:3])
x[:,1:3]=imputer.transform(x[:,1:3])

from sklearn.impute import SimpleImputer
# sklearn.impute.SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='most_frequent')

imputer.fit(X[:,3:4])
X[:,3:4]= imputer.transform(X[:,3:4])
print(X)

# Missing value

from sklearn.impute import SimpleImputer
# sklearn.impute.SimpleImputer
imputer = SimpleImputer(missing_values=np.nan, strategy='constant', fill_value= 'India')

imputer.fit(X[:,4:5])
X[:,4:5]= imputer.transform(X[:,4:5])
print(X)

from sklearn.compose import ColumnTransformer # sklearn.compose.ColumnTransformer
from sklearn.preprocessing import OneHotEncoder # sklearn.preprocessing.OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [0])], remainder='passthrough')
x = np.array(ct.fit_transform(x))

x

"""## Labeling of dependent variable (if binomial)

"""

from sklearn.preprocessing import LabelEncoder
le = LabelEncoder()
y = le.fit_transform(y)
y

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0,)
x_train, x_test, y_train, y_test

"""#SABIN DATA

## Import required libraries and read data
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
df1=pd.read_csv('/content/preprocessing_sabin.xlsx - Sheet1.csv')
df1

"""## Differentiate dependent and independent var"""

x1=df1.iloc[:,:-1].values
y1=df1.iloc[:,-1].values

x=df1.iloc[:,:-1]
y=df1.iloc[:,-1]

x1

"""## Missing values (no missing values in sabin's data)

## Transform categorical to dummy variables(for independent var)
"""

from sklearn.compose import ColumnTransformer # sklearn.compose.ColumnTransformer
from sklearn.preprocessing import OneHotEncoder # sklearn.preprocessing.OneHotEncoder
ct = ColumnTransformer(transformers=[('encoder', OneHotEncoder(), [3,5])], remainder='passthrough')
X = np.array(ct.fit_transform(x1))
X

"""## Labeling dependent varibale to binomial if its categorical (escape this step)

## Splitting the whole data into test and train set
"""

from sklearn.model_selection import train_test_split
# sklearn.model_selection.train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=0.2, random_state=0)
X_train, X_test, y_train, y_test

"""## Feature scaling (Normalizing independent variables)"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
X_train[:,-4:] = sc.fit_transform(X_train[:,-4:])
X_test[:,-4:] = sc.transform(X_test[:,-4:])

X_train, X_test