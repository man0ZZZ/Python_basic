# -*- coding: utf-8 -*-
"""Naive_Byaes_&_Random_Forest_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mf536VhxuObaMUWFhtevpv_9u5IpXd0p

# Naive Bayes Classifier Algorithm
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from google.colab import drive

drive.mount('/content/gdrive')

df_titanic=pd.read_csv('/content/gdrive/MyDrive/BDS_practice_data/Titanic-Dataset.csv')
df_titanic

len(df_titanic.index)

df_titanic.columns

"""take relevant columns for further analysis"""

df_titanic=df_titanic[['Pclass', 'Sex', 'Age','Fare','Survived']]

df_titanic.head(10)

X=df_titanic.drop('Survived',axis=1)
y=df_titanic.Survived

dum = pd.get_dummies(X.Sex)

X=pd.concat([X, dum], axis=1)
X.head(3)

"""we can drop any one dummy column(n-1) and it can still identify the values that the dummy category represent"""

X=X.drop(['Sex','male'], axis=1)
X.head(5)

X.isna().sum()

X.Age.fillna(X.Age.mean(), inplace=True)

X.isna().sum()

X=X.values
y=y.values

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=3)

from sklearn.naive_bayes import GaussianNB
nba=GaussianNB()
nba.fit(X_train,y_train)

nba.score(X_test,y_test)

nba.predict(X_test)[:20]

nba.predict_proba(X_test)[:20]

df_social=pd.read_csv('/content/gdrive/MyDrive/TakeoData/Social_Network_Ads.csv')
df_social.head(10)

from sklearn.datasets import load_iris
iris=load_iris()
iris

df_iris=pd.DataFrame(iris.data, columns=iris.feature_names)
df_iris['target']=iris.target
df_iris

y=df_iris.iloc[:,-1].values
x=df_iris.iloc[:,:-1].values

x

y

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test=train_test_split(x,y, train_size=0.25, random_state=3)

from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=20, random_state=0)
rf_model.fit(x_train, y_train)

rf_model.score(x_test,y_test)

y_test_predicted=rf_model.predict(x_test)

y_test_predicted

rf_model.predict([[6.25,3.0,5.0,1.6]])

from sklearn.metrics import confusion_matrix, f1_score, accuracy_score, recall_score, precision_score
print(confusion_matrix(y_test, y_test_predicted))
# Display accuracy score
print(accuracy_score(y_test, y_test_predicted))# Display F1 score
print(f1_score(y_test,y_test_predicted, average='weighted'))
print(recall_score(y_test,y_test_predicted,average='weighted'))
print(precision_score(y_test,y_test_predicted,average='weighted'))

"""## Plotting of Decision region
could only be done for model with two features

### random forest decision region
"""

!pip install --upgrade mlxtend

import matplotlib.pyplot as plt
import itertools
from mlxtend.plotting import plot_decision_regions
fig = plt.figure(figsize=(10, 8))
from sklearn.ensemble import RandomForestClassifier
rf_model1=RandomForestClassifier(n_estimators=20)
rf_model1.fit(x_test[:,[1,2]],y_test)
fig = plot_decision_regions(x_test[:,[1,2]], y_test,clf=rf_model1, legend=2)
plt.title('random forest')

plt.show()

"""### N_bayes classifier decision region"""

import matplotlib.pyplot as plt
from mlxtend.plotting import plot_decision_regions
from sklearn.naive_bayes import GaussianNB
bayes_model=GaussianNB()
bayes_model.fit(x_test[:,[1,2]], y_test)
nba_plot=plot_decision_regions(x_test[:,[1,2]], y_test, clf=bayes_model)
plt.show

x_test.shape

y_test.shape

y_pred_bayes=bayes_model.predict(x_test[:,[1,2]])

"""??? the average method choice in different accuracy function"""

print(bayes_model.score(x_test[:,[1,2]],y_test))
print(f1_score(y_test,y_pred_bayes, average='micro'))
print(confusion_matrix(y_test, y_pred_bayes))
print(accuracy_score(y_test, y_pred_bayes))
print(precision_score(y_test, y_pred_bayes, average='micro'))

